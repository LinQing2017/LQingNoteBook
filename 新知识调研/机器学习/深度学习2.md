---
title: 深度学习读书笔记（2）
categories: "机器学习" 
date: 2019-09-26
comments: false
toc: true
tags:
	- 深度学习
	- 读书笔记
---

一篇关于《动手学深度学习》的读书笔记。

电子书地址：https://zh.gluon.ai/

<!--more-->

# 构造模型

## 通过Block类构造模型/自定义层

```python
from mxnet import nd
from mxnet.gluon import nn

class MLP(nn.Block):
    # 声明带有模型参数的层，这里声明了两个全连接层
    def __init__(self, **kwargs):
        # 调用MLP父类Block的构造函数来进行必要的初始化。这样在构造实例时还可以指定其他函数
        # 参数，如“模型参数的访问、初始化和共享”一节将介绍的模型参数params
        super(MLP, self).__init__(**kwargs)
        self.hidden = nn.Dense(256, activation='relu')  # 隐藏层
        self.output = nn.Dense(10)  # 输出层

    # 定义模型的前向计算，即如何根据输入x计算返回所需要的模型输出
    def forward(self, x):
        return self.output(self.hidden(x))
```

- Sequential类继承自Block类，当模型的前向计算为简单串联各个层的计算时，可以通过Sequential类更简单的定义模型；
- 构造复杂模型时，需要自己定义forward函数。我们可以自己定义一个复杂的Block类型子类，然后使用Sequential将其串联起来，构成更复杂的模型。

## 模型参数的访问、初始化和共享

- 如何访问模型参数

    - Sequential构造的神经网络，可以使用中括号访问其任意一层
    - 可以使用params属性访问Block的所有参数（Parameter类型），名称如下：

        - {layer名称}_weight/weight --- .data()访问实际数值、.grad()访问其梯度
        - {layer名称}_bias/bias
    - 使用collect_params返回net所有变量的字典

- 初始化模型参数
    
    - 默认初始化: 权重参数元素为[-0.07, 0.07]之间均匀分布的随机数，偏差参数则全为0。
    - 正态分布初始化：net.initialize(init=init.Normal(sigma=0.01), force_reinit=True)
    - 常数初始化：net.initialize(init=init.Constant(1), force_reinit=True)
    - 对某个特定参数进行初始化：对Parameter类调用initalize函数
    - 自定义初始化


- 在多个层之间共享同一份模型参数（意义在于用同样的feature去提取某种特征，同时还能减少网络的权重的数目）

```python
## 中间两层共享权重
net = nn.Sequential()
shared = nn.Dense(8, activation='relu')
net.add(nn.Dense(8, activation='relu'),
        shared,
        nn.Dense(8, activation='relu', params=shared.params),
        nn.Dense(10))
net.initialize()

X = nd.random.uniform(shape=(2, 20))
net(X)

net[1].weight.data()[0] == net[2].weight.data()[0]
```
## 模型参数的延后初始化

参数延迟初始化：系统将真正的参数初始化延后到获得足够信息时才执行（获取第一个输入采样时才执行）。

通过在层中指定 in_units（输入个数）能够使initialize被调用时立即发生初始化。

## 读取和存储

- 把内存中训练好的模型参数存储在硬盘上供后续读取使用
    
    - 使用save、load读写NDArray
    - 读写Block类的模型参数，如：save_parameters 和 load_parameters

## GPU计算

- 通过ctx参数指定存储设备。
- 通过copyto函数和as_in_context函数在设备之间传输数据。
- MXNet要求计算的所有输入数据都在内存或同一块显卡的显存上。
- 用户初始化时，指定：net.initialize(ctx=mx.gpu()) ，此后计算会发生在GPU上。