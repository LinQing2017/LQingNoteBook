## Spark Core

龙腾简合的一道笔试题：简要叙述 Spark Core 的内容。

个人认为应该回答以下几个内容：

1. Spark的RDD计算模型，包括Transform算子、Action算子
2. SparkContext的相关内容：
    - Driver Application的执行与输出都是通过SparkContext来完成的，SparkContext隐藏了网络通信、分布式部署、消息通信、存储能力、计算能力、缓存、测量系统、文件服务、Web服务等内容。
    - SparkContext内置的DAGScheduler负责创建Job，将DAG中的RDD划分到不同的Stage。每个Stage内计算，通过多个Task线程并行执行。
    - 内置的TaskScheduler负责资源的申请，任务的提交及请求集群对任务的调度等工作。
3. 存储体系：Spark优先考虑使用各节点的内存作为存储，当内存不足时才会考虑使用磁盘。此外，Tachyon能够为Spark提供可靠的内存级的文件共享服务。
4. Spark的及其他模块：Spark SQL、Spark Streaming、图计算、MLIB库

## HIVE的内部表和外部表的区别

1. HDFS上数据目录不同
2. 删除内部表会直接删除元数据（metadata）及存储数据；删除外部表仅仅会删除元数据，HDFS上的文件并不会被删除； 
3. 对内部表的修改会将修改直接同步给元数据，而对外部表的表结构和分区进行修改，则需要修复（MSCK REPAIR TABLE table_name;）

## HBase 写入过程

1. 数据优先进行WAL（写HDFS目录）；

2. 数据写入内存的memstore；

3. 当内存中的memstore达到设定大小，写入HFile文件中（memstore中的kv已经是顺序的，写入到HFile的过程不需要重新排序）；

4. 当HFile不断增多时，会触发文件合并：

    minor合并：只是将小文件合并成数量较小的大文件
    
    major合并：将一个region中的一个列族的若干个HFile重写成一个新的HFile，并实际删除数据以及老化数据

## HBase表设计原则

1. 建议将HBase列族的数量设置的越少越好。
  
   原因：major合并时将region中同一个列族的HFile进行合并，列族太多影响IO、以及压缩性能。

2. 多个列族时，不同列族的数据量的差别不能太大（列族的势(Cardinality)）。

    原因：由于表的Region数目由数据量大的列族决定。这样数据量较小的列族，可能产生多个Region且分布在不同服务器，这样扫描小列族时性能会产生影响。

3. 避免使用时序或单调(递减/递增)行键，防止热点。
  
## MapReduce的基本原理，如何减少数据落盘和数据shulffe

MapReduce包括：Map过程和Reduce过程

Map：

1. 每个Map任务读取相应原始数据分片，并将数据处理成<key,value> ；
2. Map Task会对中间数据的Key进行排序，并且不断spill中间数据到磁盘；
3. 当Map Task结束后会形成一个中间文件，该文件中被分成几个部分，每个部分是不同Reduce任务的输入；

Reduce：

1. 当所有Map任务完成后，Reduce任务从不同的中间文件获取自己部分的输入；
2. Reduce进行结果处理，并且将计算结果写入到HDFS；

### Spark相比MR的优势

1. MapReduce只支持Map-Reduce一种计算模型，spark支持DAG（有向无环图）；
2. Spark有良好的Cache机制，而MR所有中间结果都要写HDFS；
3. Spark支持Streaming、图计算、Mlib多种接口，代码量更少；

## 一些体会

面试大数据相关岗位：Hive、HBase、Spark、Hadoop 是绕不过去的坎。对原理需要精通， 对我来说，尤其需要了解Hive。

